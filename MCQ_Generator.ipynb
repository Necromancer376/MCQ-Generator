{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0295f780",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\malha\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\malha\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Let\\'s explore the fascinating world of the ancient city of Petra. Petra, often referred to as the \"Rose City,\" is an archaeological wonder located in southern Jordan. Petra was the capital of the Nabatean Kingdom in the 4th century BC and later became a vital crossroads for trade and commerce, connecting the Arabian Peninsula with the Mediterranean world. This ornate temple is carved into a rose-colored rock face and has become an emblematic image of Petra. Petra\\'s unique architecture is a testament to the advanced engineering and architectural skills of the Nabateans, who harnessed the natural landscape to create a remarkable city hidden within the mountains. Petra was largely forgotten by the Western world until its rediscovery by Swiss explorer Johann Ludwig Burckhardt in 1812.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from summarizer import Summarizer\n",
    "\n",
    "# text = \"Chess is a classic two-player strategy board game that\\'s been around for centuries. The objective is to checkmate your opponent\\'s king, meaning the king is in a position to be captured (\\\"in check\\\") and there is no way to escape the threat. Each player starts with 16 pieces: one king, one queen, two rooks, two knights, two bishops, and eight pawns. The game is played on an 8x8 grid, and each type of piece has its own unique way of moving. It\\'s a game of skill, tactics, and foresight, often requiring players to think several moves ahead. Chess is not just a game of mathematical permutations and strategic moves; it\\'s also a mind sport that fosters critical thinking, patience, and creativity. Players must navigate the complexities of the board, adapting their strategies based on their opponent\\'s moves. The openings, middlegame, and endgame phases offer distinct challenges, and mastering different tactics like forks, pins, and discovered attacks can turn the tide of a match. Beyond its competitive aspect, chess is appreciated for its rich history, with countless famous games and legendary players contributing to its enduring allure.\"\n",
    "\n",
    "# text = \"Entangled particles, often referred to as qubits in the context of quantum computing, can exhibit correlated behaviors that are counterintuitive. When the state of one particle is measured, it instantly determines the state of its entangled partner, regardless of the separation between them. The phenomenon has been experimentally observed and is a crucial component in quantum computing, where it enables the development of quantum algorithms and cryptographic systems that are far more powerful and secure than classical counterparts. Quantum entanglement challenges our understanding of reality and continues to be a subject of intense research, offering exciting possibilities for the future of technology and our understanding of the quantum world\"\n",
    "\n",
    "# text = \"Space exploration has always captured the imagination of humanity, driving scientific curiosity and technological advancements. Over the decades, space agencies like NASA, ESA, and private companies such as SpaceX have launched missions to explore the cosmos. Notable achievements include the Apollo moon landings in the late 1960s and early 1970s, the exploration of Mars with rovers like Curiosity and Perseverance, and the study of distant celestial bodies with telescopes like the Hubble Space Telescope. The International Space Station (ISS) has provided a platform for international cooperation in space. Recent endeavors aim to return humans to the Moon and send astronauts to Mars, marking an exciting new chapter in space exploration. As humanity continues to push the boundaries of space, the knowledge gained not only expands our understanding of the universe but also leads to innovations that benefit life on Earth, from healthcare to environmental monitoring and sustainable energy solutions\"\n",
    "\n",
    "# text = \"Natural Language Processing (NLP) is a field of artificial intelligence that focuses on the interaction between computers and human language. It enables machines to understand, interpret, and generate human language in a way that is valuable for various applications. NLP algorithms and models are designed to handle tasks such as language translation, sentiment analysis, chatbots, and text summarization. One of the breakthroughs in NLP has been the development of transformer-based models like GPT-3, which have significantly improved the accuracy and fluency of automated language processing. NLP has wide-ranging applications, from improving customer service through chatbots to automating language translation and enhancing data analysis by extracting insights from vast amounts of unstructured text. As NLP technology continues to advance, it holds the promise of making human-computer interactions more intuitive and enabling machines to comprehend and respond to human language in increasingly sophisticated ways.\"\n",
    "\n",
    "text = \"\"\"\n",
    "Let's explore the fascinating world of the ancient city of Petra. Petra, often referred to as the \"Rose City,\" is an archaeological wonder located in southern Jordan. This UNESCO World Heritage Site is renowned for its intricate rock-cut architecture and stunning desert landscapes, making it one of the most iconic historical sites in the world. Petra was the capital of the Nabatean Kingdom in the 4th century BC and later became a vital crossroads for trade and commerce, connecting the Arabian Peninsula with the Mediterranean world. The city's most famous structure is Al-Khazneh, also known as \"The Treasury.\" This ornate temple is carved into a rose-colored rock face and has become an emblematic image of Petra. Other remarkable features of the city include the Monastery (Ad Deir), the Roman Theater, and countless tombs and chambers carved directly into the rose-red cliffs. Petra's unique architecture is a testament to the advanced engineering and architectural skills of the Nabateans, who harnessed the natural landscape to create a remarkable city hidden within the mountains. The city's strategic location made it a vital hub for caravan routes, facilitating trade in spices, silks, and other valuable goods. Petra was largely forgotten by the Western world until its rediscovery by Swiss explorer Johann Ludwig Burckhardt in 1812. Today, it stands as an archaeological marvel and a significant cultural heritage site. Visitors from around the globe are drawn to its awe-inspiring beauty, which is best experienced through a walk down the Siq, a narrow canyon that leads to the main entrance of the city. Petra's historical significance, coupled with its breathtaking architecture, has earned it a place among the New Seven Wonders of the World. It serves as a testament to the ingenuity of ancient civilizations and continues to captivate the imagination of those who venture to explore its ancient splendor.\n",
    "\"\"\"\n",
    "\n",
    "# text = \"\"\"\n",
    "# Any organisation or business becomes successful only if it is trusted by its customers and investors. When it comes to organisations working in the domain of Information Technology, Banking and Finance, Insurance or anything that directly deals with the sensitive data of customers, TRUST is the most important factor. You are out of the race the day when customers don’t trust you. The level of trust on an organisation has a direct relation with its secureness. Be it security of customer’s data, applications or in-house infrastructure, you are trusted if you are secure, along with the other obvious factors like cost, goodwill and quality of service. Here is where the concept of “Zero Trust” comes into the picture. The essence of the Zero Trust Architecture (hereafter referred as ZTA) is never trust, always verify.In the traditional systems, there are 2 zones — Trusted Zone and Untrusted Zone. The trusted zone or network is completely under control of the organisation. It typically contains the applications, servers, computers and databases sitting inside a trusted network that is protected from the outside world using devices like Firewall. These devices are within the same local area network and are controlled using things like user authentication and group policies. Here, even the physical access to the devices, servers can be controlled by defining the human beings having access to it and enabling them with access cards, passwords, physical verification etc. All the elements in the outside world are under the untrusted network. The trusted network is typically segmented from the untrusted network using demilitarised zone (DMZ). With the recent trends in information technology, most of the organisations dealing with the critical domains; as mentioned in the beginning are using web applications or services hosted on a cloud infrastructure. These applications are designed in such a way that they accessed from anywhere in the world. With the modern working culture, remote working has become popular. Users can be anywhere in the world and can still continue their work. They can even use their own devices to carry out the day to day activities. Now, these public networks or personal devices could be dangerous as they can contain malware or pose other security challenges like malwares, worms or Trojan horses. Because of this, the traditional approach of trusted and untrusted zones doesn’t seem to work. Then, what is the solution? Well, the solution is “Zero Trust”. It is not a standalone package that can be bought and implemented. Every organisation defines its own ZTA and creates policies around it. This is not a simple process. In the next few minutes, we will try to understand how the ZTA really works. This principle of ZTA says : do not trust anyone. It doesn’t matter if you are a CEO of a company sitting inside the office, a developer sitting at home or a database admin roaming in the mountains, everyone is treated the same way. Until and unless you do not verify yourself, you are an “untrusted entity”. There are multiple ways to verify yourself that could be username and password along with multi-factor authentication based on a time-based OTP or authentication token or a key. However, it does not mean that once you have verified yourself, the system will perpetually trust you. The whole essence of zero trust is “always verify”. Hence, every time the same process will be followed and you will be asked to verify yourself. We looked at the “authentication” concept here. This principle states that any user should be given only the privileges that are required to perform the task. Ex. A person from client A’s development team should not have access to client B’s development related artefacts. Similarly, a database administrator should not have access to infrastructure related controls and vice-versa. This can typically be controlled using a PIM-PAM (Privilege Identity Management and Privilege Access Management) solution that can be accessed through a VPN. This is the second level of control where the user, once authenticated, authorises himself to access the resources he has access to. Now you might say that we have perimeter security in place, we have properly implemented our ZTA, every user is properly authenticated and authorised, then why should we care about breaches? NO! It is important to keep in mind that any security breach can happen anytime. What should we do then? When a thief entres a house, he does not satisfy himself with stealing the money from one room, he empties the house and then goes away. Similarly, a hacker will try and gain access to all systems. To avoid this, it is important that critical systems and segregated from each other. Network segmentation can be done to acheive this. One can also implement all security controls in one area, generate logs from it in another and separate the applications and servers in a third controlled one. With this, the entry point does not allow the hacker to access everything. It is also important to keep a track of every activity performed. The tools used to authenticate and authorise legitimate users have the power to record the tasks performed by them while tools like SIEM, network firewall, XDRs, NIPS track the activities of an outsider. In essence, whatever is critical for an organisation should be put behind the above mentioned controls and only legitimate users should be able to access it for a single session after authenticating and authorising themselves. The typical controls to ensure this are VPNs, Active Directory or SSO, PIM-PAM solution, Perimeter devices, DLP solution etc. Whatever is non-critical to an organisation can be put under “no control”. Even if the ZTA sounds conceptually easy, it is difficult to maintain. Each organisation needs to define its policies, toolsets and implementation strategies around ZTA. A well defined and tested ZTA can protect the organisation; however, any wrongly implemented ZTA can prove to be dangerous.\n",
    "# \"\"\"\n",
    "\n",
    "# text = \"\"\"\n",
    "# India, officially known as the Republic of India, is a vast and diverse country located in South Asia. In 2003, it was a country of great historical and cultural significance. With a population of over one billion people, it was the second-most populous country in the world. India is known for its rich heritage, including a long history of civilization, art, and philosophy. The country's geography is diverse, featuring the majestic Himalayan mountain range to the north and a vast fertile plain known as the Indo-Gangetic Plain, where the majority of the population resides. India has a tropical climate in the south and a more temperate climate in the north.India is a federal parliamentary democratic republic, with a President as its head of state and a Prime Minister as the head of government. The Indian economy was experiencing significant growth in 2003, driven by its information technology and software services sector. Agriculture also played a crucial role in the economy, employing a substantial portion of the population.Culturally, India is incredibly diverse, with a multitude of languages, religions, and traditions. Hinduism, Islam, Christianity, Sikhism, Buddhism, and Jainism are among the major religions practiced in the country. India's cultural heritage includes classical art forms like Bharatanatyam, Kathak, and traditional music such as classical Hindustani and Carnatic music.In 2003, India was a vibrant and dynamic nation, with a complex tapestry of traditions, languages, and history that made it a captivating and unique place on the world stage.\n",
    "# \"\"\"\n",
    "\n",
    "# text = \"\"\"\n",
    "# For those who are interested in finding random paragraphs, that's exactly what this webpage provides. If both a random word and a random sentence aren't quite long enough for your needs, then a random paragraph might be the perfect solution. Once you arrive at this page, you'll see a random paragraph. If you need another one, all you need to do is click on the \"next paragraph\" button. If you happen to need several random paragraphs all at once, you can use this other paragraph generator. Below you can find a number of ways that this generator can be used.\n",
    "\n",
    "# Text Blocks\n",
    "# There are a number of reasons you may need a block of text and when you do, a random paragraph can be the perfect solution. If you happen to be a web designer and you need some random text to show in your layout, a random paragraph can be an excellent way to do this. If you're a programmer and you need random text to test the program, using these paragraphs can be the perfect way to do this. Anyone who's in search of realistic text for a project can use one or more of these random paragraphs to fill their need.\n",
    "\n",
    "# Improve Writing\n",
    "# For writers looking for a way to get their creative writing juices flowing, using a random paragraph can be a great way to do this. One of the great benefits of this tool is that nobody knows what is going to appear in the paragraph. This can be leveraged in a few different ways to force the writer to use creativity. For example, the random paragraph can be used as the beginning paragraph of a story that the writer must finish. I can also be used as a paragraph somewhere inside a short story, or for a more difficult creative challenge, it can be used as the ending paragraph. In every case, the writer is forced to use creativity to incorporate the random paragraph into the story.\n",
    "\n",
    "# Rewriting Skills\n",
    "# For some writers, it isn't getting the original words on paper that's the challenge, but rewriting the first and second drafts. Using the random paragraph generator can be a good way to get into a rewriting routine before beginning the project. In this case, you take the random paragraph and rewrite it so it retains the same meaning, but does so in a better and more concise way. Beginning the day doing this with a random paragraph can make the rewriting of an article, short story, or chapter of a book much easier than trying to begin directly with it.\n",
    "\n",
    "# Overcome Writers' Block\n",
    "# \"\"\"\n",
    "\n",
    "model = Summarizer()\n",
    "result = model(text, min_length=60, max_length = 500 , ratio = 0.4)\n",
    "summarized_text = ''.join(result)\n",
    "\n",
    "summarized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5cfe64cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration,T5Tokenizer\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "question_model = T5ForConditionalGeneration.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
    "question_tokenizer = T5Tokenizer.from_pretrained('ramsrigouthamg/t5_squad_v1')\n",
    "question_model = question_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acc8d496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carved',\n",
       " 'petra unique',\n",
       " 'architecture',\n",
       " 'ornate',\n",
       " 'rose',\n",
       " 'jordan petra',\n",
       " 'petra capital',\n",
       " 'city petra',\n",
       " 'petra',\n",
       " 'image petra',\n",
       " 'mediterranean',\n",
       " 'petra largely',\n",
       " 'city',\n",
       " 'mountains petra',\n",
       " 'jordan',\n",
       " 'temple',\n",
       " 'archaeological',\n",
       " 'petra petra',\n",
       " 'petra referred']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "keywords =[]\n",
    "kw_model = KeyBERT(model='all-mpnet-base-v2')\n",
    "for i in range(1,3):\n",
    "    keywords_raw = kw_model.extract_keywords(summarized_text, \n",
    "                                             keyphrase_ngram_range=(1, i), \n",
    "                                             stop_words='english', \n",
    "                                             highlight=False, \n",
    "                                             top_n=10)\n",
    "    keywords.extend(list(dict(keywords_raw).keys()))\n",
    "\n",
    "keywords = list(set(keywords))\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3d6c602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How is the ornate temple of Petra made?\n",
      "Carved\n",
      "\n",
      "\n",
      "What is a testament to the advanced engineering of the Nabateans?\n",
      "Petra unique\n",
      "\n",
      "\n",
      "What is a testament to the advanced engineering and skills of the Nabateans?\n",
      "Architecture\n",
      "\n",
      "\n",
      "What type of temple is Petra's emblematic image?\n",
      "Ornate\n",
      "\n",
      "\n",
      "What color rock face is Petra's temple carved into?\n",
      "Rose\n",
      "\n",
      "\n",
      "Where is Rose City located?\n",
      "Jordan petra\n",
      "\n",
      "\n",
      "What was the name of the Nabatean Kingdom in the 4th century BC?\n",
      "Petra capital\n",
      "\n",
      "\n",
      "What ancient city is located in southern Jordan?\n",
      "City petra\n",
      "\n",
      "\n",
      "What was the capital of Nabatean Kingdom in the 4th century BC?\n",
      "Petra\n",
      "\n",
      "\n",
      "What is the name of the ornate temple in Petra?\n",
      "Image petra\n",
      "\n",
      "\n",
      "Petra was the capital of what kingdom in the 4th century BC?\n",
      "Mediterranean\n",
      "\n",
      "\n",
      "What was the capital of the Nabatean Kingdom?\n",
      "Petra largely\n",
      "\n",
      "\n",
      "What is Petra often referred to as?\n",
      "City\n",
      "\n",
      "\n",
      "Where is the city of Petra located?\n",
      "Mountains petra\n",
      "\n",
      "\n",
      "Where is Petra located?\n",
      "Jordan\n",
      "\n",
      "\n",
      "What is carved into a rose-colored rock face?\n",
      "Temple\n",
      "\n",
      "\n",
      "What type of wonder is Petra?\n",
      "Archaeological\n",
      "\n",
      "\n",
      "What is the name of the ancient city in southern Jordan?\n",
      "Petra petra\n",
      "\n",
      "\n",
      "What is the \"Rose City\" often called?\n",
      "Petra referred\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def get_question(context,answer,model,tokenizer):\n",
    "  text = \"context: {} answer: {}\".format(context,answer)\n",
    "  encoding = tokenizer.encode_plus(text,max_length=384, \n",
    "                                   pad_to_max_length=False,truncation=True, \n",
    "                                   return_tensors=\"pt\").to(device)\n",
    "  input_ids, attention_mask = encoding[\"input_ids\"], encoding[\"attention_mask\"]\n",
    "\n",
    "  outs = model.generate(input_ids=input_ids,\n",
    "                                  attention_mask=attention_mask,\n",
    "                                  early_stopping=True,\n",
    "                                  num_beams=5,\n",
    "                                  num_return_sequences=1,\n",
    "                                  no_repeat_ngram_size=2,\n",
    "                                  max_length=72)\n",
    "\n",
    "  dec = [tokenizer.decode(ids,skip_special_tokens=True) for ids in outs]\n",
    "\n",
    "  Question = dec[0].replace(\"question:\",\"\")\n",
    "  Question= Question.strip()\n",
    "  return Question\n",
    "\n",
    "\n",
    "question_answer_dict = {}\n",
    "\n",
    "for answer in keywords:\n",
    "    ques = get_question(summarized_text,answer,question_model,question_tokenizer)\n",
    "    print (ques)\n",
    "    print (answer.capitalize())\n",
    "    print (\"\\n\")\n",
    "    question_answer_dict[ques] = answer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4edeaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sense2vec import Sense2Vec\n",
    "s2v = Sense2Vec().from_disk('s2v_old')\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_transformer_model = SentenceTransformer('msmarco-distilbert-base-v3')\n",
    "from similarity.normalized_levenshtein import NormalizedLevenshtein\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "normalized_levenshtein = NormalizedLevenshtein()\n",
    "\n",
    "def filter_same_sense_words(original,wordlist):\n",
    "  filtered_words=[]\n",
    "  base_sense =original.split('|')[1] \n",
    "\n",
    "  for eachword in wordlist:\n",
    "    if eachword[0].split('|')[1] == base_sense:\n",
    "      filtered_words.append(eachword[0].split('|')[0].replace(\"_\", \" \").title().strip())\n",
    "  return filtered_words\n",
    "\n",
    "def get_highest_similarity_score(wordlist,wrd):\n",
    "  score=[]\n",
    "  for each in wordlist:\n",
    "    score.append(normalized_levenshtein.similarity(each.lower(),wrd.lower()))\n",
    "  return max(score)\n",
    "\n",
    "def sense2vec_get_words(word,s2v,topn,question):\n",
    "    output = []\n",
    "\n",
    "    try:\n",
    "      sense = s2v.get_best_sense(word, senses= [\"NOUN\", \"PERSON\",\"PRODUCT\",\"LOC\",\"ORG\",\"EVENT\",\"NORP\",\"WORK OF ART\",\"FAC\",\"GPE\",\"NUM\",\"FACILITY\"])\n",
    "      most_similar = s2v.most_similar(sense, n=topn)\n",
    "      output = filter_same_sense_words(sense,most_similar)\n",
    "    except:\n",
    "      output =[]\n",
    "\n",
    "    threshold = 0.6\n",
    "    final=[word]\n",
    "    checklist =question.split()\n",
    "    for x in output:\n",
    "      if get_highest_similarity_score(final,x)<threshold and x not in final and x not in checklist:\n",
    "        final.append(x)\n",
    "    \n",
    "    return final[1:]\n",
    "\n",
    "def mmr(doc_embedding, word_embeddings, words, top_n, lambda_param):\n",
    "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embedding)\n",
    "    word_similarity = cosine_similarity(word_embeddings)\n",
    "\n",
    "    keywords_idx = [np.argmax(word_doc_similarity)]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    for _ in range(top_n - 1):\n",
    "        candidate_similarities = word_doc_similarity[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        mmr = (lambda_param) * candidate_similarities - (1-lambda_param) * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # Update keywords & candidates\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7cc8b2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distractors (word,origsentence,sense2vecmodel,sentencemodel,top_n,lambdaval):\n",
    "    distractors = sense2vec_get_words(word,sense2vecmodel,top_n,origsentence)\n",
    "\n",
    "    if len(distractors) ==0:\n",
    "        return distractors\n",
    "    \n",
    "    distractors_new = [word.capitalize()]\n",
    "    distractors_new.extend(distractors)\n",
    "\n",
    "    embedding_sentence = origsentence+ \" \"+word.capitalize()\n",
    "\n",
    "    keyword_embedding = sentencemodel.encode([embedding_sentence])\n",
    "    distractor_embeddings = sentencemodel.encode(distractors_new)\n",
    "\n",
    "    max_keywords = min(len(distractors_new),5)\n",
    "    filtered_keywords = mmr(keyword_embedding, distractor_embeddings,distractors_new,max_keywords,lambdaval)\n",
    "    final = [word.capitalize()]\n",
    "\n",
    "    for wrd in filtered_keywords:\n",
    "        if wrd.lower() !=word.lower():\n",
    "            final.append(wrd.capitalize())\n",
    "    final = final[1:]\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f3cc172",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1] Using the random paragraph generator can be a good way to get into what routine?\n",
      "A rewriting\n",
      "B Origins\n",
      "C Explicit reference\n",
      "D Formalization\n",
      "\n",
      "2] What can be used as the ending of a short story?\n",
      "A Whole text\n",
      "B Bullet point\n",
      "C paragraph\n",
      "D Opening paragraph\n",
      "\n",
      "3] What can a random paragraph force the writer to use?\n",
      "A Sophistication\n",
      "B Lateral thinking\n",
      "C creativity\n",
      "D Technical skill\n",
      "\n",
      "4] What can be used to force the writer to use creativity?\n",
      "A Footnotes\n",
      "B Bullet points\n",
      "C paragraphs\n",
      "D Extra words\n",
      "\n",
      "5] What type of paragraph can be used when you need a block of text?\n",
      "A random\n",
      "B Insert\n",
      "C Types\n",
      "D Map\n",
      "\n",
      "6] What type of text can be used to force a writer to use creativity?\n",
      "A Footers\n",
      "B Single tile\n",
      "C blocks\n",
      "D Ramps\n",
      "\n",
      "7] What type of block can be used for a number of reasons?\n",
      "A Hyperlinks\n",
      "B Comment box\n",
      "C text\n",
      "D Speech program\n",
      "\n",
      "8] What type of text can be used to force the writer to use creativity?\n",
      "A block\n",
      "B Exit\n",
      "C Perimeter\n",
      "D Strip\n",
      "\n",
      "9] A random paragraph can be used to force who to use creativity?\n",
      "A writer\n",
      "B Story teller\n",
      "C Screenplay\n",
      "D Director\n",
      "\n",
      "10] Where can you find random paragraphs?\n",
      "A Search page\n",
      "B webpage\n",
      "C Actual website\n",
      "D Pdf.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "q_no = 1\n",
    "\n",
    "for question , answer in question_answer_dict.items():\n",
    "    distractors = get_distractors(answer,question,s2v,sentence_transformer_model,40,0.2)\n",
    "    if len(distractors) != 0 :\n",
    "        print(\"%d] %s\" %(q_no, question))\n",
    "        options = random.sample(distractors, 3 if len(distractors)>=3 else len(distractors))\n",
    "        options.append(answer)\n",
    "        random.shuffle(options)\n",
    "        \n",
    "        for (i, option) in enumerate(options, start=1):\n",
    "            print(chr(64+i), option)\n",
    "        \n",
    "        q_no += 1\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbda5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
